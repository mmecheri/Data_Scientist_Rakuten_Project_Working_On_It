{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541f8701",
   "metadata": {},
   "source": [
    " # 1️⃣ Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f440b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rakuten Benchmark Analysis - Image Model (ResNet50)\n",
    "## Introduction\n",
    "Ce notebook analyse le modèle utilisé par le benchmark Rakuten pour la classification d’images.\n",
    "\n",
    "Le modèle est basé sur **ResNet50 pré-entraîné sur ImageNet** avec **27 couches décongelées**, incluant **8 couches convolutionnelles**.\n",
    "\n",
    "L’objectif est de :\n",
    "- **Comprendre l’architecture du benchmark**.\n",
    "- **Reproduire le modèle utilisé**.\n",
    "- **Évaluer ses performances** sur le dataset Rakuten.\n",
    "- **Déterminer des axes d’amélioration** pour surpasser ce modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563809e",
   "metadata": {},
   "source": [
    " # 2️⃣Import des Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1780f8",
   "metadata": {},
   "source": [
    " # 3️⃣ Présentation du Modèle Image du Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f2ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modèle utilisé dans le benchmark Rakuten\n",
    "Le modèle d’image utilisé dans le benchmark est **ResNet50 pré-entraîné sur ImageNet**.  \n",
    "**Modifications apportées :**\n",
    "- **27 couches supérieures décongelées**.\n",
    "- **8 couches convolutionnelles entraînées**.\n",
    "- **Entraînement effectué avec un jeu de données non précisé (batch size, learning rate inconnus)**.\n",
    "\n",
    "**Nombre de paramètres :**\n",
    "- **12,144,667 paramètres entraînables**.\n",
    "- **23,643,035 paramètres non entraînables**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90d433",
   "metadata": {},
   "source": [
    "# 3️⃣ Chargement et Prétraitement des Donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768983e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des paramètres\n",
    "IMG_SIZE = (224, 224)  # Taille probable utilisée dans le benchmark\n",
    "BATCH_SIZE = 64\n",
    "DATA_DIR = \"path_to_images\"  # Remplace par ton chemin d'accès\n",
    "\n",
    "# Prétraitement des images avec normalisation\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, \"image_train\"),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, \"image_train\"),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccef12",
   "metadata": {},
   "source": [
    "# 4️⃣ Chargement et Prétraitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des paramètres\n",
    "IMG_SIZE = (224, 224)  # Taille probable utilisée dans le benchmark\n",
    "BATCH_SIZE = 64\n",
    "DATA_DIR = \"path_to_images\"  # Remplace par ton chemin d'accès\n",
    "\n",
    "# Prétraitement des images avec normalisation\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, \"image_train\"),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, \"image_train\"),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869262a",
   "metadata": {},
   "source": [
    "# 5️⃣ Reproduction du Modèle ResNet50 Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle pré-entraîné ResNet50\n",
    "base_model = keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "# Décongélation des 27 dernières couches\n",
    "for layer in base_model.layers[:-27]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Ajout des couches finales pour la classification\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73334e6e",
   "metadata": {},
   "source": [
    " # 6️⃣ Évaluation du Modèle Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c6ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle (facultatif si modèle déjà entraîné)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Courbes d'apprentissage\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Courbe d'Apprentissage - Benchmark Rakuten (ResNet50)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44227fb",
   "metadata": {},
   "source": [
    "# 7️⃣ Conclusion & Pistes d'Amélioration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a384285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Résumé des performances du benchmark :\n",
    "- **Weighted-F1 score : 0.5534**\n",
    "- **Points forts :** Utilisation de ResNet50, fine-tuning de 27 couches.\n",
    "- **Limites :** Résultats relativement faibles, manque d’optimisation.\n",
    "\n",
    "## Stratégie pour améliorer le benchmark :\n",
    "1️⃣ **Tester d'autres modèles CNN pré-entraînés** (InceptionResNetV2, Xception, DenseNet121).  \n",
    "2️⃣ **Optimiser les hyperparamètres** (batch size, learning rate, nombre de couches à fine-tuner).  \n",
    "3️⃣ **Appliquer des techniques avancées d'augmentation de données** (rotation, shear, contrast, etc.).  \n",
    "4️⃣ **Fusionner les prédictions texte + image** pour obtenir un modèle multimodal performant.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
