{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c31ba52",
   "metadata": {},
   "source": [
    "# 1 Introduction & Objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7ad32",
   "metadata": {},
   "source": [
    "## üìå Benchmarking CNN Model for Text Classification\n",
    "\n",
    "### üéØ Objective:\n",
    "- Replicate the reference CNN model from the Rakuten challenge.\n",
    "- Train it on the **designation** field (product titles).\n",
    "- Evaluate using **Weighted F1-score** to compare with the benchmark (**0.8113**).\n",
    "\n",
    "### üîç Expected Outcome:\n",
    "- Establish a **baseline** for text classification.\n",
    "- Compare the F1-score with **0.8113**.\n",
    "- Prepare for **improvements (Fine-tuning, Hyperparameter Optimization)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a3297",
   "metadata": {},
   "source": [
    "# 2. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beec36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Reshape, Conv2D, MaxPooling2D, Concatenate, Flatten, Dropout, Dense\n",
    ")\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f721e8",
   "metadata": {},
   "source": [
    "# 3. D√©finition du mod√®le benchmark\n",
    "\n",
    "## Mod√®le utilis√© dans le benchmark Rakuten\n",
    "https://challengedata.ens.fr/participants/challenges/35/\n",
    "*For the text data a simplified CNN classifier used. Only the designation fields (product titles) are used in this benchmark model. The input size is the maximum possible designation length, 34 in this case. Shorter inputs are zero-padded. The architecture consists of an embedding layer and 6 convolutional, max-pooling blocks. The embeddings are trained with the entire architecture. Following is the model architecture:*\n",
    "\n",
    "| Layer (type)          | Output Shape         | Number of Params | Connected to                   |\n",
    "|-----------------------|---------------------|------------------|--------------------------------|\n",
    "| InputLayer           | (None, 34)          | 0                | -                              |\n",
    "| Embedding Layer      | (None, 34, 300)     | 17,320,500       | InputLayer                     |\n",
    "| Reshape             | (None, 34, 300, 1)  | 0                | Embedding Layer                |\n",
    "| Conv2D Block 1      | (None, 34, 1, 512)  | 154,112          | Reshape                        |\n",
    "| MaxPooling2D Block 1 | (None, 1, 1, 512)   | 0                | Conv2D Block 1                 |\n",
    "| Conv2D Block 2      | (None, 33, 1, 512)  | 307,712          | Reshape                        |\n",
    "| MaxPooling2D Block 2 | (None, 1, 1, 512)   | 0                | Conv2D Block 2                 |\n",
    "| Conv2D Block 3      | (None, 32, 1, 512)  | 461,312          | Reshape                        |\n",
    "| MaxPooling2D Block 3 | (None, 1, 1, 512)   | 0                | Conv2D Block 3                 |\n",
    "| Conv2D Block 4      | (None, 31, 1, 512)  | 614,912          | Reshape                        |\n",
    "| MaxPooling2D Block 4 | (None, 1, 1, 512)   | 0                | Conv2D Block 4                 |\n",
    "| Conv2D Block 5      | (None, 30, 1, 512)  | 768,512          | Reshape                        |\n",
    "| MaxPooling2D Block 5 | (None, 1, 1, 512)   | 0                | Conv2D Block 5                 |\n",
    "| Conv2D Block 6      | (None, 29, 1, 512)  | 922,112          | Reshape                        |\n",
    "| MaxPooling2D Block 6 | (None, 1, 1, 512)   | 0                | Conv2D Block 6                 |\n",
    "| Concatenate         | (None, 6, 1, 512)   | 0                | All MaxPooling2D Blocks        |\n",
    "| Flatten            | (None, 3072)        | 0                | Concatenate                    |\n",
    "| Dropout Layer       | (None, 3072)        | 0                | Flatten                        |\n",
    "| Dense Layer         | (None, 27)         | 8,297            | Dropout Layer                  |\n",
    "\n",
    "\n",
    "- This architecture contains total **20,632,143 trainable** parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19847d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_SEQUENCE_LENGTH = 34  # Max length of designation field\n",
    "EMBEDDING_DIM = 300       # Embedding dimension from benchmark\n",
    "NUM_CLASSES = 27          # Number of product categories\n",
    "\n",
    "def create_cnn_text_model():\n",
    "    # Input layer\n",
    "    input_text = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "\n",
    "    # Embedding Layer\n",
    "    embedding = Embedding(input_dim=20000, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(input_text)\n",
    "    \n",
    "    # Reshape for Conv2D\n",
    "    reshape = Reshape((MAX_SEQUENCE_LENGTH, EMBEDDING_DIM, 1))(embedding)\n",
    "\n",
    "    # 6 Convolution + MaxPooling blocks\n",
    "    conv_blocks = []\n",
    "    for filter_size in range(1, 7):\n",
    "        conv = Conv2D(filters=512, kernel_size=(filter_size, EMBEDDING_DIM), activation=\"relu\")(reshape)\n",
    "        pool = MaxPooling2D(pool_size=(conv.shape[1], 1))(conv)\n",
    "        conv_blocks.append(pool)\n",
    "\n",
    "    # Concatenate all convolution outputs\n",
    "    concatenated = Concatenate(axis=1)(conv_blocks)\n",
    "\n",
    "    # Flatten and Dropout\n",
    "    flatten = Flatten()(concatenated)\n",
    "    dropout = Dropout(0.5)(flatten)\n",
    "\n",
    "    # Fully Connected Output Layer\n",
    "    output = Dense(NUM_CLASSES, activation=\"softmax\")(dropout)\n",
    "\n",
    "    # Compile Model\n",
    "    model = Model(inputs=input_text, outputs=output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_cnn_text_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8310151",
   "metadata": {},
   "source": [
    "# 4. Iteration 1: Without text cleaning (to match the benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e9ddfa",
   "metadata": {},
   "source": [
    "## Iteration 1: Without Text Cleaning\n",
    "*Following the benchmark approach, we apply tokenization directly to the raw `designation` field without any preprocessing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f075bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df_train = pd.read_csv(\"data/raw_csv/X_train_update.csv\")\n",
    "df_test = pd.read_csv(\"data/raw_csv/X_test_update.csv\")\n",
    "df_labels = pd.read_csv(\"data/raw_csv/Y_train_CVw08PX.csv\")\n",
    "\n",
    "# Merge train data with labels\n",
    "df_train = df_train.merge(df_labels, left_index=True, right_index=True)\n",
    "\n",
    "# Tokenization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 34\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(df_train[\"designation\"])\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(df_train[\"designation\"]), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(df_test[\"designation\"]), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "y_train = df_train[\"prdtypecode\"].values  # Target labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d8b10e",
   "metadata": {},
   "source": [
    "## Iteration 2: With Text Cleaning\n",
    "*Now, we apply standard text preprocessing techniques before tokenization:*\n",
    "   - Lowercasing\n",
    "    - Removing punctuation & special characters\n",
    "   - Removing extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df_train[\"designation_cleaned\"] = df_train[\"designation\"].astype(str).apply(clean_text)\n",
    "df_test[\"designation_cleaned\"] = df_test[\"designation\"].astype(str).apply(clean_text)\n",
    "\n",
    "# Tokenization on cleaned text\n",
    "tokenizer_cleaned = Tokenizer(num_words=20000)\n",
    "tokenizer_cleaned.fit_on_texts(df_train[\"designation_cleaned\"])\n",
    "\n",
    "X_train_cleaned = pad_sequences(tokenizer_cleaned.texts_to_sequences(df_train[\"designation_cleaned\"]), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test_cleaned = pad_sequences(tokenizer_cleaned.texts_to_sequences(df_test[\"designation_cleaned\"]), maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b70d0",
   "metadata": {},
   "source": [
    "# 5. Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16a791",
   "metadata": {},
   "source": [
    "We train our model separately on:\n",
    "\n",
    "- **Iteration 1**: Raw text (designation)\n",
    "- **Iteration 2**: Cleaned text (designation_cleaned)\n",
    "- epochs=10,\n",
    "- batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac360a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on raw text\n",
    "model_raw = create_text_cnn_model()\n",
    "history_raw = model_raw.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Train model on cleaned text\n",
    "model_cleaned = create_text_cnn_model()\n",
    "history_cleaned = model_cleaned.fit(X_train_cleaned, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eda56e",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88138e",
   "metadata": {},
   "source": [
    "## 6.1 Learning Curves: Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curves(history, title):\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history_raw, 'Learning Curve - Raw Text')\n",
    "plot_learning_curves(history_cleaned, 'Learning Curve - Cleaned Text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3373c3e7",
   "metadata": {},
   "source": [
    "## 6.2  Evaluation Metrics: Weighted F1-Score, Precision & Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642964e8",
   "metadata": {},
   "source": [
    "- **F1-score weighted**\n",
    "- **Pr√©cision**\n",
    "- **Recal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c3cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label):\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(f'üìå {label}')\n",
    "    print(f'üîπ Weighted F1-score: {f1:.4f}')\n",
    "    print(f'üîπ Precision: {precision:.4f}')\n",
    "    print(f'üîπ Recall: {recall:.4f}\\\\n')\n",
    "\n",
    "evaluate_model(model_raw, X_test, df_test[\"prdtypecode\"].values, 'Raw Text')\n",
    "evaluate_model(model_cleaned, X_test_cleaned, df_test[\"prdtypecode\"].values, 'Cleaned Text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a17ca",
   "metadata": {},
   "source": [
    "## 6.3 Detailed Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def generate_classification_report(model, X_test, y_test, label):\n",
    "    \"\"\"Generates a detailed classification report for the given model.\"\"\"\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'üìå {label} - Classification Report:')\n",
    "    print(report)\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Generate reports for both cases\n",
    "generate_classification_report(model_raw, X_test, df_test[\"prdtypecode\"].values, \"Raw Text\")\n",
    "generate_classification_report(model_cleaned, X_test_cleaned, df_test[\"prdtypecode\"].values, \"Cleaned Text\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05110b2",
   "metadata": {},
   "source": [
    "## 6.4 Confusion Matrix: Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad77658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(model, X_test, y_test, label, class_labels):\n",
    "    \"\"\"Generates and plots a confusion matrix for the given model.\"\"\"\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(f\"Confusion Matrix - {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Get class labels\n",
    "class_labels = df_train[\"prdtypecode\"].unique()\n",
    "\n",
    "# Generate confusion matrices for both cases\n",
    "plot_confusion_matrix(model_raw, X_test, df_test[\"prdtypecode\"].values, \"Raw Text\", class_labels)\n",
    "plot_confusion_matrix(model_cleaned, X_test_cleaned, df_test[\"prdtypecode\"].values, \"Cleaned Text\", class_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800769d",
   "metadata": {},
   "source": [
    "# 8. Benchmark Results & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a6db5",
   "metadata": {},
   "source": [
    "## üîπ Results: Raw Text Model\n",
    "- **Benchmark F1-score (given)**: `0.8113`\n",
    "- **Our Model F1-score**: `____`  \n",
    "- **Precision**: `____` \n",
    "- **Recall**: `____` \n",
    "\n",
    "## üîπ Results: Cleaned Text Model\n",
    "- **Benchmark F1-score (given)**: `0.8113`\n",
    "- **Our Model F1-score**: `____`  \n",
    "- **Precision**: `____` \n",
    "- **Recall**: `{`____` \n",
    "\n",
    "## üîπ Next Steps:\n",
    "‚úÖ Compare **baseline** with **Hyperparameter Optimization**.  \n",
    "‚úÖ Perform **Pretrained Embeddings** (`Word2Vec, FastText, GloVe`).  \n",
    "‚úÖ Train **BiLSTM or Transformer-based models** (e.g., BERT).  \n",
    "‚úÖ Integrate **Multimodal (Text + Image) classification** (`05_Bimodal_Integration`).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795dfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
