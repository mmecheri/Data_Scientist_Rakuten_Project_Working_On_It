{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be41c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rackuten_project_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e22be5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path : directory où se trouve les DF Final cleand containing Labels , classes number changed , image_name\n",
    "path= 'D:/DataScienTest_WorkSpace/WS/Travail_Final/Datasets/'\n",
    "\n",
    "# Callback outputs , hdf5 files \n",
    "path_output_models = 'D:/DataScienTest_WorkSpace/WS/Travail_Final/Trained_models/Conv1D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b282d92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>text</th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>labels</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>olivia personalisiertes notizbuch seiten punkt...</td>\n",
       "      <td>0</td>\n",
       "      <td>adult books</td>\n",
       "      <td>image_1263597046_product_3804725264.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>journal arts art marche salon art asiatique pa...</td>\n",
       "      <td>18</td>\n",
       "      <td>magazines</td>\n",
       "      <td>image_1008141237_product_436067568.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "      <td>2</td>\n",
       "      <td>video games accessories</td>\n",
       "      <td>image_938777978_product_201115110.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>peluche donald europe disneyland marionnette d...</td>\n",
       "      <td>7</td>\n",
       "      <td>toys for children</td>\n",
       "      <td>image_457047496_product_50418756.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>guerre tuques luc grandeur veut organiser jeu ...</td>\n",
       "      <td>25</td>\n",
       "      <td>books</td>\n",
       "      <td>image_1077757786_product_278535884.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \\\n",
       "0                                               <NA>  3804725264  1263597046   \n",
       "1                                               <NA>   436067568  1008141237   \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978   \n",
       "3                                               <NA>    50418756   457047496   \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786   \n",
       "\n",
       "                                                text  prdtypecode  \\\n",
       "0  olivia personalisiertes notizbuch seiten punkt...            0   \n",
       "1  journal arts art marche salon art asiatique pa...           18   \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...            2   \n",
       "3  peluche donald europe disneyland marionnette d...            7   \n",
       "4  guerre tuques luc grandeur veut organiser jeu ...           25   \n",
       "\n",
       "                    labels                               image_name  \n",
       "0              adult books  image_1263597046_product_3804725264.jpg  \n",
       "1                magazines   image_1008141237_product_436067568.jpg  \n",
       "2  video games accessories    image_938777978_product_201115110.jpg  \n",
       "3        toys for children     image_457047496_product_50418756.jpg  \n",
       "4                    books   image_1077757786_product_278535884.jpg  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = pd.read_pickle(path + 'df_train_final.pkl')\n",
    "xtrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73eedfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = pd.DataFrame(xtrain['prdtypecode']).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55e4cf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3116,\n",
       " 1: 2508,\n",
       " 2: 1681,\n",
       " 3: 832,\n",
       " 4: 2671,\n",
       " 5: 3953,\n",
       " 6: 764,\n",
       " 7: 4870,\n",
       " 8: 2070,\n",
       " 9: 5045,\n",
       " 10: 807,\n",
       " 11: 2491,\n",
       " 12: 3241,\n",
       " 13: 5073,\n",
       " 14: 4303,\n",
       " 15: 803,\n",
       " 16: 4993,\n",
       " 17: 824,\n",
       " 18: 4760,\n",
       " 19: 4774,\n",
       " 20: 1421,\n",
       " 21: 4989,\n",
       " 22: 2589,\n",
       " 23: 10209,\n",
       " 24: 2496,\n",
       " 25: 2761,\n",
       " 26: 872}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(ytrain, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa26c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ytrain\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19c26035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "94b937ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(xtrain['text'], y, test_size=0.2, random_state=1234)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7a3e2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 20000)#default was 10000/best 20000\n",
    "\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(text_train)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(text_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "#print(text_train.shape)\n",
    "#print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "34f96d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 400 #defautl was 250, best 400\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "#print(\"X_train\", len(X_train))\n",
    "#print(\"X_test\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd51cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ededfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTMCell\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, GlobalMaxPooling1D, RNN, GRUCell, Dropout, concatenate, SpatialDropout1D, Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f81d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving Callbacks and history results\n",
    "#path_output_models = 'D:/DataScienTest_WorkSpace/WS/Rackupy_WS/Travail_Final/Trained_models/'\n",
    "date_result = '13022022'\n",
    "nbr_Epochs = 50\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6dc33",
   "metadata": {},
   "source": [
    "# CONV1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bbbb09e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 400, 100)          12494000  \n",
      "                                                                 \n",
      " spatial_dropout1d_13 (Spati  (None, 400, 100)         0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 399, 64)           12864     \n",
      "                                                                 \n",
      " global_max_pooling1d_13 (Gl  (None, 64)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 27)                1755      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,508,619\n",
      "Trainable params: 12,508,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_conv1D = Sequential()\n",
    "\n",
    "model_conv1D.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model_conv1D.add(layers.SpatialDropout1D(0.2))\n",
    "model_conv1D.add(layers.Conv1D(64, 2, activation='relu'))\n",
    "model_conv1D.add(layers.GlobalMaxPooling1D())\n",
    "model_conv1D.add(layers.Dense(27, activation='softmax'))\n",
    "\n",
    "         \n",
    "model_conv1D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b608d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =  0.001\n",
    "\n",
    "model_conv1D.compile(optimizer= Adam(learning_rate= learning_rate), #  0.001 , default LR\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fffc2",
   "metadata": {},
   "source": [
    "***Callback***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "be58f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "file_name_checkpnt = 'checkpoint_Conv1D_' + date_result +  \\\n",
    "                                       '_LR_'+str(learning_rate) +'_' + str(nbr_Epochs)+ 'Epochs.h5'\n",
    "\n",
    "#Sauvegarder les meilleurs poids du modèle au cours de l'entraînement :\n",
    "checkpoint = ModelCheckpoint(filepath = path_output_models + file_name_checkpnt , \n",
    "                             monitor ='val_accuracy',\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True, # (pour que le meilleur modèle ne soit pas écrasé)\n",
    "                             save_weights_only = False,\n",
    "                             mode ='max', #(permet de préciser si la métrique doit croître ou décroitre : ici on choisit 'min'\n",
    "                                           #car la métrique est une perte à minimiser)\n",
    "                             save_freq='epoch')\n",
    "#Arrêter l'entraînement si le modèle n'évolue plus (très pratique pour ne pas gérer le\n",
    "#nombre d'epoch) :\n",
    "# A modifier pour avoir des \n",
    "early = EarlyStopping(monitor='val_loss',                    \n",
    "                      min_delta = 0,\n",
    "                      patience = 10, #(nombre d'epochs à attendre avant d'arrêter l'entraînement\n",
    "                      restore_best_weights = True,\n",
    "                      verbose = 1,\n",
    "                      mode = 'min')\n",
    "\n",
    "#lr_reduce = ReduceLROnPlateau(patience=2,\n",
    "  #                             verbose=1)\n",
    "\n",
    "callbacks = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e71be552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/DataScienTest_WorkSpace/WS/Travail_Final/Trained_models/Conv1D/checkpoint_Conv1D_13022022_LR_0.001_50Epochs.h5'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_output_models + file_name_checkpnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c61500c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "339/340 [============================>.] - ETA: 0s - loss: 1.9466 - accuracy: 0.4775\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70425, saving model to D:/DataScienTest_WorkSpace/WS/Travail_Final/Trained_models/Conv1D\\checkpoint_Conv1D_13022022_LR_0.001_50Epochs.h5\n",
      "340/340 [==============================] - 5s 13ms/step - loss: 1.9446 - accuracy: 0.4781 - val_loss: 1.0733 - val_accuracy: 0.7043\n",
      "Epoch 2/50\n",
      "337/340 [============================>.] - ETA: 0s - loss: 0.8262 - accuracy: 0.7700\n",
      "Epoch 00002: val_accuracy improved from 0.70425 to 0.77555, saving model to D:/DataScienTest_WorkSpace/WS/Travail_Final/Trained_models/Conv1D\\checkpoint_Conv1D_13022022_LR_0.001_50Epochs.h5\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.8259 - accuracy: 0.7699 - val_loss: 0.7755 - val_accuracy: 0.7756\n",
      "Epoch 3/50\n",
      "339/340 [============================>.] - ETA: 0s - loss: 0.5595 - accuracy: 0.8395\n",
      "Epoch 00003: val_accuracy improved from 0.77555 to 0.79133, saving model to D:/DataScienTest_WorkSpace/WS/Travail_Final/Trained_models/Conv1D\\checkpoint_Conv1D_13022022_LR_0.001_50Epochs.h5\n",
      "340/340 [==============================] - 4s 13ms/step - loss: 0.5593 - accuracy: 0.8396 - val_loss: 0.6998 - val_accuracy: 0.7913\n",
      "Epoch 4/50\n",
      "340/340 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8856\n",
      "Epoch 00004: val_accuracy improved from 0.79133 to 0.80122, saving model to D:/DataScienTest_WorkSpace/WS/Travail_Final/Trained_models/Conv1D\\checkpoint_Conv1D_13022022_LR_0.001_50Epochs.h5\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.4067 - accuracy: 0.8856 - val_loss: 0.6830 - val_accuracy: 0.8012\n",
      "Epoch 5/50\n",
      "339/340 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.9165\n",
      "Epoch 00005: val_accuracy improved from 0.80122 to 0.80323, saving model to D:/DataScienTest_WorkSpace/WS/Travail_Final/Trained_models/Conv1D\\checkpoint_Conv1D_13022022_LR_0.001_50Epochs.h5\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.3021 - accuracy: 0.9164 - val_loss: 0.6904 - val_accuracy: 0.8032\n",
      "Epoch 6/50\n",
      "336/340 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9374\n",
      "Epoch 00006: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.2311 - accuracy: 0.9373 - val_loss: 0.7193 - val_accuracy: 0.8008\n",
      "Epoch 7/50\n",
      "340/340 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.9535\n",
      "Epoch 00007: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.1788 - accuracy: 0.9535 - val_loss: 0.7481 - val_accuracy: 0.7998\n",
      "Epoch 8/50\n",
      "339/340 [============================>.] - ETA: 0s - loss: 0.1431 - accuracy: 0.9631\n",
      "Epoch 00008: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.1431 - accuracy: 0.9631 - val_loss: 0.7834 - val_accuracy: 0.8012\n",
      "Epoch 9/50\n",
      "338/340 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9701\n",
      "Epoch 00009: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.1161 - accuracy: 0.9701 - val_loss: 0.8198 - val_accuracy: 0.7993\n",
      "Epoch 10/50\n",
      "337/340 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9739\n",
      "Epoch 00010: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.0994 - accuracy: 0.9739 - val_loss: 0.8589 - val_accuracy: 0.7972\n",
      "Epoch 11/50\n",
      "338/340 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9784\n",
      "Epoch 00011: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.0853 - accuracy: 0.9784 - val_loss: 0.8950 - val_accuracy: 0.7967\n",
      "Epoch 12/50\n",
      "340/340 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9803\n",
      "Epoch 00012: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.0754 - accuracy: 0.9803 - val_loss: 0.9354 - val_accuracy: 0.7935\n",
      "Epoch 13/50\n",
      "337/340 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9821\n",
      "Epoch 00013: val_accuracy did not improve from 0.80323\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.0681 - accuracy: 0.9821 - val_loss: 0.9635 - val_accuracy: 0.7938\n",
      "Epoch 14/50\n",
      "338/340 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9836\n",
      "Epoch 00014: val_accuracy did not improve from 0.80323\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.0613 - accuracy: 0.9836 - val_loss: 1.0034 - val_accuracy: 0.7933\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_conv1D = model_conv1D.fit(X_train, y_train.values,\n",
    "    batch_size = 200,\n",
    "    epochs = nbr_Epochs,\n",
    "    validation_data = [X_test, y_test.values],\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aa151ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.8012\n"
     ]
    }
   ],
   "source": [
    "valid_score_conv1D = model_conv1D.evaluate(X_test, y_test.values, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fa71df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_conv1D = model_conv1D.predict(X_test)\n",
    "#Appliquer la méthode argmax du tableau y_pred pour obtenir les classes les plus probable\n",
    "\n",
    "y_pred_class_conv1D = y_pred_conv1D.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b5f9f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.8012\n",
      "Accuracy: 80.12%\n",
      "Loss:  0.6829662919044495\n",
      "Wall time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Get the accuracy score\n",
    "valid_score = model_conv1D.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(valid_score[1] * 100)) \n",
    "print(\"Loss: \",valid_score[0])\n",
    "Conv1D_SC = np.round((valid_score[1] * 100), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a9c97",
   "metadata": {},
   "source": [
    "***Save  results***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "67f6f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_hist = 'history_Conv1D_' + date_result +  \\\n",
    "                                       '_LR_'+str(learning_rate) + '_SC_' + str(Conv1D_SC) + '%_' + str(nbr_Epochs)+ 'Epochs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1656cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history_conv1D.history) \n",
    "\n",
    "# history to json:  \n",
    "hist_json_file = path_output_models + file_name_hist + '.json'\n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# history to csv: \n",
    "hist_csv_file = path_output_models + file_name_hist +'.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "# history to pickle file\n",
    "hist_df.to_pickle(path_output_models + file_name_hist +'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dfa92",
   "metadata": {},
   "source": [
    "***Save trained model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "92dc7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'history_Conv1D_' + date_result +  \\\n",
    "                                       '_LR_'+str(learning_rate) + '_SC_' + str(Conv1D_SC) + '%_' + str(nbr_Epochs)+ 'Epochs.hdf5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
