{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f70a7e",
   "metadata": {},
   "source": [
    "# Rakuten France Multimodal Product Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d04cc",
   "metadata": {},
   "source": [
    "## üìåProject Overview  \n",
    "\n",
    "This project was carried out as part of a challenge organized by **Rakuten** and our **Data Scientist training** at **DataScientest**.  \n",
    "\n",
    "The challenge focuses on **e-commerce product classification**, using a **bimodal approach** that integrates both **textual and image data**.  \n",
    "\n",
    "The goal is to predict the **product type code** (**prdtypecode**) for each product by combining:  \n",
    "- **Text data** ‚Üí Product name (`designation`) and description (`description`).  \n",
    "- **Image data** ‚Üí Product images from the **Rakuten France catalog**.  \n",
    "\n",
    "A **baseline model** is provided on the **challenge website**, with separate models for text and images:  \n",
    "\n",
    "- **RNN (Recurrent Neural Network) for text data** ‚Üí **0.8113 weighted F1-score**  \n",
    "- **ResNet (Residual Neural Network) for image data** ‚Üí **0.5534 weighted F1-score**  \n",
    "\n",
    "### üéØObjective: Outperforming the Baseline with a Multimodal Approach  \n",
    "Unlike the baseline models that treat text and images separately, our approach is to develop a **multimodal model** that combines both data sources to improve classification performance and ***outperform the baseline results***.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92204249",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f0a855",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "For this challenge, **Rakuten France** provides approximately **99,000** product listings in CSV format, comprising both the training set (**84,916** entries) and the test set (**13,812** entries).\n",
    "\n",
    "The data is organized into four distinct files:\n",
    "\n",
    "- `X_train_update.csv`: Training samples containing textual descriptions and references to associated image files.\n",
    "- `y_train_CVw08PX.csv`: Contains the target variable (**prdtypecode**).\n",
    "- `X_test_update.csv`: Test samples for result submission.\n",
    "- `images.zip`: This archive includes all images:\n",
    "  - `image_train`: Contains **84,916** images for training.\n",
    "  - `image_test`: Contains **13,812** images for testing.\n",
    "\n",
    "Each product entry includes a **designation** (product title), an optional **description**, and an associated **image**. The objective is to utilize both textual and visual data to predict the product type code (**prdtypecode**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f0335",
   "metadata": {},
   "source": [
    "### **Sample Data Illustration**\n",
    "\n",
    "Below is an extract from the training dataset (`X_train`):\n",
    "\n",
    "![Training Data Sample](../reports/figures/Xtrain_sample_view.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### **X_train Fields**\n",
    "Each product entry in `X_train` consists of the following fields:\n",
    "\n",
    "- **`Id`**: A unique integer ID assigned to each product. It is used to associate the product with its corresponding **product type code (`prdtypecode`)**.\n",
    "- **`designation`**: The product title, a short text summarizing the product.\n",
    "- **`description`**: A detailed textual description of the product. This field may contain missing values since not all products have a description.\n",
    "- **`productid`**: A unique identifier for each product.\n",
    "- **`imageid`**: A unique identifier for the image linked to the product.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Class Labels (`prdtypecode`)**\n",
    "The dataset contains multiple product categories, each identified by a **product type code (`prdtypecode`)**, which serves as the target variable for classification.\n",
    "\n",
    "Below is an overview of the class distribution in `y_train`:\n",
    "\n",
    "![Product Classes](../reports/figures/ytrain_sample_view.png)\n",
    "\n",
    "#### üìå *Image file names follow the format:*  \n",
    "*`image_<imageid>_product_<productid>.jpg`*\n",
    "\n",
    "---\n",
    "\n",
    "#### **Example: X_train Record with Associated Image**\n",
    "The following example illustrates a **product entry**, displaying both **its textual information and the corresponding image**:\n",
    "\n",
    "\n",
    "![Text and Image Example](../reports/figures/text_with_image_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1557935",
   "metadata": {},
   "source": [
    "## üîÑ Next Steps  \n",
    "\n",
    "Now that we have a clear understanding of the dataset, the next steps involve **exploring and analyzing the data**.  \n",
    "\n",
    "üìå **2_CSV_Exploration_and_Visualization.ipynb**  \n",
    "- Load and inspect structured data (CSV files).  \n",
    "- Perform exploratory data analysis (EDA) and visualize key insights.  \n",
    "\n",
    "üìå **3_Image_Exploration.ipynb**  \n",
    "- Verify the availability of image files.  \n",
    "- Analyze image properties (size, format, distribution).  \n",
    "- Display a sample of product images.  \n",
    "\n",
    "These steps will help us understand the **data structure, quality, and consistency** before proceeding to **data preprocessing and modeling**.  \n",
    "\n",
    "‚û°Ô∏è **Proceed to ` 2_CSV_Exploration_and_Visualization.ipynb` to start the analysis!**  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
