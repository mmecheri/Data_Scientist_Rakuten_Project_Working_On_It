{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a3a4f1",
   "metadata": {},
   "source": [
    "# Word Clouds for Text Product Categories\n",
    "\n",
    "## ðŸ“ŒObjectives of the Notebook\n",
    "\n",
    "In this notebook, we will explore and visualize the text data associated with product codes using Word Clouds. This will help us better understand the most frequent words for each category and identify potential patterns.\n",
    "\n",
    "## Key Steps:\n",
    "âœ” **Loading pre-cleaned text data**  â†’ Import processed datasets (`X_train_cleaned.pkl` & `X_test_cleaned.pkl`).       \n",
    "âœ”  **Generating and visualizing Word Clouds** â†’ Extract and display the most frequent words for each product category.   \n",
    "âœ”  **Identifying Product Category Labels from Word Cloud Analysis**    \n",
    "âœ”  **Mapping product codes to labels** â†’ Assign descriptive category names to product codes for better interpretability.  \n",
    "âœ”  **Saving the labeled dataset** â†’ Store the final processed data (`X_train_labeled.pkl) for future use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e4c70",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b46dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "import matplotlib  \n",
    "import importlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d3f0e",
   "metadata": {},
   "source": [
    "### Setting Up Project Paths and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97caa9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current notebook directory\n",
    "CURRENT_DIR = Path(os.getcwd()).resolve()\n",
    "\n",
    "# Automatically find the project root (go up 1 level)\n",
    "PROJECT_ROOT = CURRENT_DIR.parents[1]\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Function to get relative paths from project root\n",
    "def get_relative_path(absolute_path):\n",
    "    return str(Path(absolute_path).relative_to(PROJECT_ROOT))\n",
    "\n",
    "# Print project root directory\n",
    "print(f\"Project Root Directory: {PROJECT_ROOT.name}\")  # Display only the root folder name\n",
    "\n",
    "import config  # Now Python can find config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5aab18",
   "metadata": {},
   "source": [
    "## 2. Load Pickle Files (X_test_cleaned.pkl & X_test_cleaned.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdce12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)  # Reload config to ensure any updates are applied\n",
    "\n",
    "# Define paths for datasets (FILES, not directories)\n",
    "train_pickle_path = Path(config.INTERIM_TEXT_DIR) / \"X_train_cleaned.pkl\"\n",
    "test_pickle_path = Path(config.INTERIM_TEXT_DIR) / \"X_test_cleaned.pkl\"\n",
    "y_train_pickle_path = Path(config.INTERIM_TEXT_DIR) / \"y_train.pkl\"\n",
    "\n",
    "# Function to get relative paths from project root\n",
    "def get_relative_path(absolute_path: Path):\n",
    "    \"\"\"Returns the relative path from the project root.\"\"\"\n",
    "    return str(absolute_path.relative_to(config.BASE_DIR))\n",
    "\n",
    "# Function to load a Pickle file safely\n",
    "def load_pickle(file_path: Path, dataset_name: str):\n",
    "    \"\"\"Loads a pickle file with error handling and basic visualization.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"Error: `{dataset_name}` file not found at {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        data = pd.read_pickle(file_path)\n",
    "        print(f\"Successfully loaded `{dataset_name}` | Shape: {data.shape}\")\n",
    "\n",
    "        if not data.empty:\n",
    "            display(data.head())  # Display first rows\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading `{dataset_name}`: {e}\")\n",
    "        return None\n",
    "\n",
    "# List of required files with their names\n",
    "required_files = {\n",
    "    \"Training Dataset\": train_pickle_path,\n",
    "    \"Testing Dataset\": test_pickle_path,   \n",
    "    \"Training Labels\": y_train_pickle_path\n",
    "}\n",
    "\n",
    "# Check if files exist before loading\n",
    "for name, path in required_files.items():\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Error: `{name}` file not found at {get_relative_path(path)}\")\n",
    "\n",
    "# Load datasets\n",
    "X_train = load_pickle(train_pickle_path, \"X_train_cleaned.pkl\")\n",
    "X_test = load_pickle(test_pickle_path, \"X_test_cleaned.pkl\")\n",
    "y_train = load_pickle(y_train_pickle_path, \"y_train.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3304bf",
   "metadata": {},
   "source": [
    "## 3. Generating and Visualizing Word Clouds\n",
    "\n",
    "Word Clouds help us quickly identify the most frequent words in each product category. This can provide insights into key terms associated with different categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd18b6f",
   "metadata": {},
   "source": [
    "### 3.1  Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062198af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad522f9",
   "metadata": {},
   "source": [
    "### 3.2 Get unique product code values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a889fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === Get unique product codes === #\n",
    "unique_product_codes = np.unique(X_train[\"prdtypecode\"])\n",
    "\n",
    "# Display unique values\n",
    "print(\"Unique Product Codes:\")\n",
    "print(unique_product_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fec9f6",
   "metadata": {},
   "source": [
    "### 3.3 Define a Function to Generate Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Global dictionary to store top words per category\n",
    "word_freq_dict = {}\n",
    "\n",
    "def plot_wordcloud(category, data, column=\"text\"):\n",
    "    \"\"\"\n",
    "    Generate and display a Word Cloud for a given product category,\n",
    "    and store the most frequent words in a global dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - category (int): The product category code to visualize.\n",
    "    - data (DataFrame): The dataset containing text data.\n",
    "    - column (str): The column containing the text (default: \"text\").\n",
    "    \"\"\"\n",
    "    text_data = \" \".join(data[data[\"prdtypecode\"] == category][column].dropna())\n",
    "    \n",
    "    # Generate the Word Cloud\n",
    "    wc = WordCloud(\n",
    "        background_color=\"black\",  # Set background color to black for better contrast\n",
    "        max_words=100,             # Limit the number of words displayed in the Word Cloud\n",
    "        max_font_size=50,          # Set the maximum font size for the largest words\n",
    "        random_state=42            # Ensure reproducibility\n",
    "    ).generate(text_data)\n",
    "\n",
    "    # Extract most frequent words\n",
    "    word_frequencies = wc.words_  # Dictionary {word: frequency}\n",
    "    top_words = Counter(word_frequencies).most_common(10)  # Get top 10 words\n",
    "\n",
    "    # Store in global dictionary\n",
    "    word_freq_dict[category] = top_words\n",
    "\n",
    "    # Print most frequent words for the category\n",
    "    print(f\"\\n Most frequent words for category {category}:\")\n",
    "    for word, freq in top_words:\n",
    "        print(f\"   {word}: {freq:.4f}\")\n",
    "\n",
    "    # Display the Word Cloud\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for {category}\", fontsize=14)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c7131",
   "metadata": {},
   "source": [
    "### 3.4 Generating Word Clouds for All Product Code Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7b413e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_wordcloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13064\\1663004500.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_wordcloud' is not defined"
     ]
    }
   ],
   "source": [
    "plot_wordcloud(10, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5450c5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_wordcloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13064\\4211033711.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_wordcloud' is not defined"
     ]
    }
   ],
   "source": [
    "plot_wordcloud(40, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda18eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(50, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d06895",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(60, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1140, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f200dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1160, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dca2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1180, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1280, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a698dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1281, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1300, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37131d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1301, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b406f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1302, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1320, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d61ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1560, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1920, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(1940, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be59783",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2060, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e92fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2220, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1bb09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2280, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2403, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950af541",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2462, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2522, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2582, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2583, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2585, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2705, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5714e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(2905, X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635c486",
   "metadata": {},
   "source": [
    "### 3.5 Summary: Most Frequent Words by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary: Most Frequent Words by Product Category\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for category, words in word_freq_dict.items():\n",
    "    top_words = \", \".join([word for word, freq in words])\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Product Code {category:<5} | {top_words}\")\n",
    "\n",
    "print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86923231",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prdtypecode = {\n",
    "    \"prdtypecode\": [10, 40, 50, 60, 1140, 1160, 1180, 1280, 1281, 1300, \n",
    "                    1301, 1302, 1320, 1560, 1920, 1940, 2060, 2220, 2280, \n",
    "                    2403, 2462, 2522, 2582, 2583, 2585, 2705, 2905],  \n",
    " \n",
    "    \"Label\": [\"adult books\", \"imported video games\", \"video games accessories\", \"games and consoles\", \n",
    "              \"figurines and Toy Pop\", \"playing cards\", \"figurines, masks and role playing games\", \n",
    "              \"toys for children\", \"board games\", \"remote controlled models\", \"accessories children\", \n",
    "              \"toys, outdoor playing, clothes\", \"early childhood\", \"interior furniture and bedding\", \n",
    "              \"interior accessories\", \"Food\", \"decoration interior\", \"supplies for domestic animals\", \n",
    "              \"magazines\", \"children books and magazines\", \"games\", \"stationery\", \n",
    "              \"furniture kitchen and garden\", \"piscine spa\", \"gardening and DIY\", \"books\", \n",
    "              \"online distribution of video games\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06958172",
   "metadata": {},
   "source": [
    "### 3.6 ðŸ“Œ Identifying Product Category Labels from Word Cloud Analysis\n",
    "\n",
    "By analyzing the **Word Cloud visualizations** and the **summary of most frequent words**, we were able to accurately identify the product categories associated with each `prdtypecode`. Below is the final mapping of **product categories to their respective product codes**:  \n",
    "\n",
    "| **Product Code** | **Identified Category** |  \n",
    "|-----------------|------------------------|  \n",
    "| 10             | Adult Books |  \n",
    "| 40             | Imported Video Games |  \n",
    "| 50             | Video Games Accessories |  \n",
    "| 60             | Games and Consoles |  \n",
    "| 1140           | Figurines and Toy Pop |  \n",
    "| 1160           | Playing Cards |  \n",
    "| 1180           | Figurines, Masks, and Role-Playing Games |  \n",
    "| 1280           | Toys for Children |  \n",
    "| 1281           | Board Games |  \n",
    "| 1300           | Remote Controlled Models |  \n",
    "| 1301           | Accessories for Children |  \n",
    "| 1302           | Toys, Outdoor Playing, and Clothes |  \n",
    "| 1320           | Early Childhood |  \n",
    "| 1560           | Interior Furniture and Bedding |  \n",
    "| 1920           | Interior Accessories |  \n",
    "| 1940           | Food |  \n",
    "| 2060           | Decoration Interior |  \n",
    "| 2220           | Supplies for Domestic Animals |  \n",
    "| 2280           | Magazines |  \n",
    "| 2403           | Children Books and Magazines |  \n",
    "| 2462           | Games |  \n",
    "| 2522           | Stationery |  \n",
    "| 2582           | Furniture, Kitchen, and Garden |  \n",
    "| 2583           | Piscine and Spa |  \n",
    "| 2585           | Gardening and DIY |  \n",
    "| 2705           | Books |  \n",
    "| 2905           | Online Distribution of Video Games |  \n",
    "\n",
    " This labeling will now be used for further analysis and model training.  \n",
    " ðŸ“Œ **We will now add these category labels to our training dataset (`X_train`).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd4a2a",
   "metadata": {},
   "source": [
    "### 3.7 Adding Category Labels to X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef252f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping of prdtypecode to category labels\n",
    "dict_code_label = {\n",
    "    10: \"Adult Books\",\n",
    "    40: \"Imported Video Games\",\n",
    "    50: \"Video Games Accessories\",\n",
    "    60: \"Games and Consoles\",\n",
    "    1140: \"Figurines and Toy Pop\",\n",
    "    1160: \"Playing Cards\",\n",
    "    1180: \"Figurines, Masks, and Role-Playing Games\",\n",
    "    1280: \"Toys for Children\",\n",
    "    1281: \"Board Games\",\n",
    "    1300: \"Remote Controlled Models\",\n",
    "    1301: \"Accessories for Children\",\n",
    "    1302: \"Toys, Outdoor Playing, and Clothes\",\n",
    "    1320: \"Early Childhood\",\n",
    "    1560: \"Interior Furniture and Bedding\",\n",
    "    1920: \"Interior Accessories\",\n",
    "    1940: \"Food\",\n",
    "    2060: \"Decoration Interior\",\n",
    "    2220: \"Supplies for Domestic Animals\",\n",
    "    2280: \"Magazines\",\n",
    "    2403: \"Children Books and Magazines\",\n",
    "    2462: \"Games\",\n",
    "    2522: \"Stationery\",\n",
    "    2582: \"Furniture, Kitchen, and Garden\",\n",
    "    2583: \"Piscine and Spa\",\n",
    "    2585: \"Gardening and DIY\",\n",
    "    2705: \"Books\",\n",
    "    2905: \"Online Distribution of Video Games\"\n",
    "}\n",
    "\n",
    "#  Add the category labels to X_train\n",
    "X_train[\"Label\"] = X_train[\"prdtypecode\"].map(dict_code_label)\n",
    "\n",
    "# Display a sample to verify\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949c902",
   "metadata": {},
   "source": [
    "# 4. Saving Updated Datasets for Future Use\n",
    "\n",
    "To avoid reloading and recomputing the datasets in every notebook, we save the cleaned and labeled training dataset as a Pickle file. This ensures that we can efficiently reuse the data in future steps without the need for redundant preprocessing.\n",
    "\n",
    "The datasets will be saved in the **`processed`** directory as follows:\n",
    "\n",
    "- **Training dataset**: `X_train_final.pkl`\n",
    "\n",
    "To ensure consistency in subsequent steps, we also save the target variable `y_train` and the test dataset `X_test`, even though they have not been modified in the current notebook.\n",
    "\n",
    "- **Training target variable (prdtypecode)**: `y_train_final.pkl`  \n",
    "  (Saved for consistency, even though it hasn't been modified.)\n",
    "\n",
    "- **Testing dataset**: `X_test_final.pkl`  \n",
    "  (Saved for future use, especially for challenge submissions, as it has no associated target variable for labeling.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Define the directory and file name\n",
    "# pickle_dir = \"../../data/processed/\"\n",
    "pickle_dir = Path(config.PROCESSED_DIR)\n",
    "os.makedirs(pickle_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths for the labeled datasets\n",
    "train_pickle_path = os.path.join(pickle_dir, \"X_train_final.pkl\")\n",
    "test_pickle_path = os.path.join(pickle_dir, \"X_test_final.pkl\")\n",
    "target_pickle_path = os.path.join(pickle_dir, \"y_train_final.pkl\")  # Path for y_train\n",
    "\n",
    "try:\n",
    "    # Save updated training dataset\n",
    "    X_train.to_pickle(train_pickle_path)\n",
    "    print(f\"Training dataset saved: {train_pickle_path}\")\n",
    "\n",
    "    # Save test dataset (even if it hasn't been modified)\n",
    "    X_test.to_pickle(test_pickle_path)\n",
    "    print(f\"Test dataset saved: {test_pickle_path}\")\n",
    "\n",
    "    # Save the training target variable (even if it hasn't been modified)\n",
    "    y_train.to_pickle(target_pickle_path)\n",
    "    print(f\"Training target variable saved: {target_pickle_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saving datasets: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93a7bb",
   "metadata": {},
   "source": [
    "## 5. ðŸ”„ Next Steps\n",
    "\n",
    "We have utilized word clouds to visualize the most frequent terms within product categories. Assigning descriptive labels to product codes based on this analysis will enhance our understanding of these categories, thereby facilitating more insightful analysis of prediction results.\n",
    "\n",
    "**Next, we will:**\n",
    "\n",
    "- **Vectorize the text data**: Convert the cleaned text into numerical representations suitable for Machine Learning Models.  \n",
    "âž¡ï¸ This will be accomplished in the upcoming notebook  **`6_ML_Text_Vectorization_TF.ipynb`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06462813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
