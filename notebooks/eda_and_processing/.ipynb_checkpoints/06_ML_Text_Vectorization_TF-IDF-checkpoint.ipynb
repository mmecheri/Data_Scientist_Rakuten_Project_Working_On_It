{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65532141",
   "metadata": {},
   "source": [
    "#  Text Vectorization with TF-IDF  \n",
    "\n",
    "\n",
    "This notebook processes cleaned text data using **TF-IDF vectorization** and prepares both **training (`Xtrain_matrix.pkl`)** and **test (`Xtest_matrix.pkl`)** feature matrices. Additionally, it converts the target labels into numerical format (`ytrain.pkl`).  \n",
    "\n",
    "By the end of this notebook, we will save:  \n",
    "- **`Xtrain_matrix.pkl`** → TF-IDF matrix for training data  \n",
    "- **`Xtest_matrix.pkl`** → TF-IDF matrix for test data  \n",
    "- **`tfidf_vectorizer.pkl`** → The trained TF-IDF vectorizer  \n",
    "- **`y_train_encoded`** → Processed target labels  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66b7c2",
   "metadata": {},
   "source": [
    " ## 1. Load Preprocessed Data\n",
    "Before applying TF-IDF, we first load the finals cleaned datasets (`X_train_final.pkl` and `X_test_final.pkl`).  \n",
    "Additionally, we load the target labels (`y_train_final.pkl`) to transform them into a format suitable for model training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31b1dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded `X_train_final.pkl` | Shape: (84916, 8)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>10</td>\n",
       "      <td>image_1263597046_product_3804725264.jpg</td>\n",
       "      <td>olivia personalisiertes notizbuch seiten punkt...</td>\n",
       "      <td>Adult Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>2280</td>\n",
       "      <td>image_1008141237_product_436067568.jpg</td>\n",
       "      <td>journal arts art marche salon art asiatique pa...</td>\n",
       "      <td>Magazines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>50</td>\n",
       "      <td>image_938777978_product_201115110.jpg</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "      <td>Video Games Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>1280</td>\n",
       "      <td>image_457047496_product_50418756.jpg</td>\n",
       "      <td>peluche donald europe disneyland marionnette d...</td>\n",
       "      <td>Toys for Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>2705</td>\n",
       "      <td>image_1077757786_product_278535884.jpg</td>\n",
       "      <td>guerre tuques luc idees grandeur veut organise...</td>\n",
       "      <td>Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \\\n",
       "0                                               <NA>  3804725264  1263597046   \n",
       "1                                               <NA>   436067568  1008141237   \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978   \n",
       "3                                               <NA>    50418756   457047496   \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786   \n",
       "\n",
       "   prdtypecode                               image_name  \\\n",
       "0           10  image_1263597046_product_3804725264.jpg   \n",
       "1         2280   image_1008141237_product_436067568.jpg   \n",
       "2           50    image_938777978_product_201115110.jpg   \n",
       "3         1280     image_457047496_product_50418756.jpg   \n",
       "4         2705   image_1077757786_product_278535884.jpg   \n",
       "\n",
       "                                                text                    Label  \n",
       "0  olivia personalisiertes notizbuch seiten punkt...              Adult Books  \n",
       "1  journal arts art marche salon art asiatique pa...                Magazines  \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...  Video Games Accessories  \n",
       "3  peluche donald europe disneyland marionnette d...        Toys for Children  \n",
       "4  guerre tuques luc idees grandeur veut organise...                    Books  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded `X_test_final.pkl` | Shape: (13812, 6)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84916</th>\n",
       "      <td>Folkmanis Puppets - 2732 - Marionnette Et Théâ...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>516376098</td>\n",
       "      <td>1019294171</td>\n",
       "      <td>image_1019294171_product_516376098.jpg</td>\n",
       "      <td>folkmanis puppets marionnette theatre mini turtle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84917</th>\n",
       "      <td>Porte Flamme Gaxix - Flamebringer Gaxix - 136/...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>133389013</td>\n",
       "      <td>1274228667</td>\n",
       "      <td>image_1274228667_product_133389013.jpg</td>\n",
       "      <td>porte flamme gaxix flamebringer twilight dragons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84918</th>\n",
       "      <td>Pompe de filtration Speck Badu 95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4128438366</td>\n",
       "      <td>1295960357</td>\n",
       "      <td>image_1295960357_product_4128438366.jpg</td>\n",
       "      <td>pompe filtration speck badu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84919</th>\n",
       "      <td>Robot de piscine électrique</td>\n",
       "      <td>&lt;p&gt;Ce robot de piscine d&amp;#39;un design innovan...</td>\n",
       "      <td>3929899732</td>\n",
       "      <td>1265224052</td>\n",
       "      <td>image_1265224052_product_3929899732.jpg</td>\n",
       "      <td>robot piscine electrique robot design innovant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84920</th>\n",
       "      <td>Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>152993898</td>\n",
       "      <td>940543690</td>\n",
       "      <td>image_940543690_product_152993898.jpg</td>\n",
       "      <td>hsm destructeur securio coupe croise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             designation  \\\n",
       "84916  Folkmanis Puppets - 2732 - Marionnette Et Théâ...   \n",
       "84917  Porte Flamme Gaxix - Flamebringer Gaxix - 136/...   \n",
       "84918                  Pompe de filtration Speck Badu 95   \n",
       "84919                        Robot de piscine électrique   \n",
       "84920  Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...   \n",
       "\n",
       "                                             description   productid  \\\n",
       "84916                                               <NA>   516376098   \n",
       "84917                                               <NA>   133389013   \n",
       "84918                                               <NA>  4128438366   \n",
       "84919  <p>Ce robot de piscine d&#39;un design innovan...  3929899732   \n",
       "84920                                               <NA>   152993898   \n",
       "\n",
       "          imageid                               image_name  \\\n",
       "84916  1019294171   image_1019294171_product_516376098.jpg   \n",
       "84917  1274228667   image_1274228667_product_133389013.jpg   \n",
       "84918  1295960357  image_1295960357_product_4128438366.jpg   \n",
       "84919  1265224052  image_1265224052_product_3929899732.jpg   \n",
       "84920   940543690    image_940543690_product_152993898.jpg   \n",
       "\n",
       "                                                    text  \n",
       "84916  folkmanis puppets marionnette theatre mini turtle  \n",
       "84917   porte flamme gaxix flamebringer twilight dragons  \n",
       "84918                        pompe filtration speck badu  \n",
       "84919  robot piscine electrique robot design innovant...  \n",
       "84920               hsm destructeur securio coupe croise  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded `y_train_final.pkl` | Shape: (84916, 1)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prdtypecode\n",
       "0           10\n",
       "1         2280\n",
       "2           50\n",
       "3         1280\n",
       "4         2705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "train_pickle_path = \"../../data/processed/X_train_final.pkl\"  \n",
    "test_pickle_path = \"../../data/processed/X_test_final.pkl\"\n",
    "y_train_pickle_path = \"../../data/processed/y_train_final.pkl\" \n",
    "\n",
    "# Function to load a Pickle file safely\n",
    "def load_pickle(file_path, dataset_name):\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            data = pd.read_pickle(file_path)\n",
    "            print(f\"Successfully loaded `{dataset_name}` | Shape: {data.shape}\\n\")\n",
    "            display(data.head())  # Display first few rows\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading `{dataset_name}`: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    return None\n",
    "\n",
    "# Load both datasets\n",
    "X_train  = load_pickle(train_pickle_path, \"X_train_final.pkl\")\n",
    "X_test = load_pickle(test_pickle_path, \"X_test_final.pkl\")\n",
    "y_train = load_pickle(y_train_pickle_path, \"y_train_final.pkl\")\n",
    "\n",
    "\n",
    "# # Extract text column\n",
    "# train_text = X_train['text']\n",
    "# test_text = X_test['text']\n",
    "\n",
    "# print(\"✅ Data successfully loaded!\")\n",
    "# print(f\"Training samples: {train_text.shape[0]}, Test samples: {test_text.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f13f0",
   "metadata": {},
   "source": [
    "## 2. Convert and Save Target Labels\n",
    "\n",
    "\n",
    "The `prdtypecode` column contains **product category codes**, which need to be converted into numerical labels ranging from 0 to 26.  \n",
    "This ensures that our classification model understands the target variable correctly.  \n",
    "After conversion, we save the processed labels as ``y_train_encoded.pkl`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eae99d",
   "metadata": {},
   "source": [
    "### 2.1 From previous Notebook : *5_WordClouds_for_Text_Product_Categories.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f0dfb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# From previous Notebook : 5_WordClouds_for_Text_Product_Categories\n",
    "dict_code_label = {\n",
    "    10: \"Adult Books\",\n",
    "    40: \"Imported Video Games\",\n",
    "    50: \"Video Games Accessories\",\n",
    "    60: \"Games and Consoles\",\n",
    "    1140: \"Figurines and Toy Pop\",\n",
    "    1160: \"Playing Cards\",\n",
    "    1180: \"Figurines, Masks, and Role-Playing Games\",\n",
    "    1280: \"Toys for Children\",\n",
    "    1281: \"Board Games\",\n",
    "    1300: \"Remote Controlled Models\",\n",
    "    1301: \"Accessories for Children\",\n",
    "    1302: \"Toys, Outdoor Playing, and Clothes\",\n",
    "    1320: \"Early Childhood\",\n",
    "    1560: \"Interior Furniture and Bedding\",\n",
    "    1920: \"Interior Accessories\",\n",
    "    1940: \"Food\",\n",
    "    2060: \"Decoration Interior\",\n",
    "    2220: \"Supplies for Domestic Animals\",\n",
    "    2280: \"Magazines\",\n",
    "    2403: \"Children Books and Magazines\",\n",
    "    2462: \"Games\",\n",
    "    2522: \"Stationery\",\n",
    "    2582: \"Furniture, Kitchen, and Garden\",\n",
    "    2583: \"Piscine and Spa\",\n",
    "    2585: \"Gardening and DIY\",\n",
    "    2705: \"Books\",\n",
    "    2905: \"Online Distribution of Video Games\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662af21c",
   "metadata": {},
   "source": [
    "### 2.2 Convert product codes to numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "471c608e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train - print(\"Comparison: Original vs. Encoded Labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original prdtypecode</th>\n",
       "      <th>prdtypecode_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2522</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2582</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original prdtypecode  prdtypecode_encoded\n",
       "0                    10                    0\n",
       "1                  2280                    1\n",
       "2                    50                    2\n",
       "3                  1280                    3\n",
       "4                  2705                    4\n",
       "5                  2280                    1\n",
       "6                    10                    0\n",
       "7                  2522                    5\n",
       "8                  1280                    3\n",
       "9                  2582                    6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train - Display the comparison between original and encoded labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original prdtypecode</th>\n",
       "      <th>prdtypecode_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2522</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1280</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2582</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original prdtypecode  prdtypecode_encoded\n",
       "0                    10                    0\n",
       "1                  2280                    1\n",
       "2                    50                    2\n",
       "3                  1280                    3\n",
       "4                  2705                    4\n",
       "5                  2280                    1\n",
       "6                    10                    0\n",
       "7                  2522                    5\n",
       "8                  1280                    3\n",
       "9                  2582                    6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert product codes to numerical labels\n",
    "prdtypecodes = list(y_train['prdtypecode'].unique())  # Extract unique product categories\n",
    "target_mapping = {code: i for i, code in enumerate(prdtypecodes)}  # Create mapping {prdtypecode: numeric_label}\n",
    "\n",
    "# Apply mapping to create numerical target labels\n",
    "y_train_encoded = y_train['prdtypecode'].map(target_mapping)\n",
    "\n",
    "# Ensure integer format\n",
    "y_train_encoded = y_train_encoded.astype('int64')\n",
    "# ─────────────────────────────────────────────────────────────────────────────── #\n",
    "\n",
    "X_train[\"prdtypecode_encoded\"] = X_train[\"prdtypecode\"].map(target_mapping)\n",
    "\n",
    "# Ensure integer format\n",
    "X_train[\"prdtypecode_encoded\"] = X_train[\"prdtypecode_encoded\"].astype(\"int64\")\n",
    "\n",
    "# Reorder columns to place \"Encoded target\" right after \"prdtypecode\"\n",
    "columns_order = [\n",
    "    \"designation\", \"description\", \"productid\", \"imageid\", \"prdtypecode\", \n",
    "    \"prdtypecode_encoded\", \"Label\", \"image_name\", \"text\"\n",
    "]\n",
    "\n",
    "# Apply the new column order\n",
    "X_train = X_train[columns_order]\n",
    "\n",
    "# Display the comparison between original and encoded labels\n",
    "# ─────────────────────────────────────────────────────────────────────────────── #\n",
    "comparison_df_y_train = pd.DataFrame({\n",
    "    \"Original prdtypecode\": y_train['prdtypecode'].head(10),  # 10 first rows before encoding\n",
    "    \"prdtypecode_encoded\": y_train_encoded.head(10)  # 10 first rows after encoding\n",
    "})\n",
    "\n",
    "print('y_train - print(\"Comparison: Original vs. Encoded Labels')\n",
    "display(comparison_df_y_train)\n",
    "# Display the comparison between original and encoded labels\n",
    "\n",
    "comparison_df_X_train = pd.DataFrame({\n",
    "    \"Original prdtypecode\": X_train['prdtypecode'].head(10),  # 10 first rows before encoding\n",
    "    \"prdtypecode_encoded\": X_train['prdtypecode_encoded'].head(10)# 10 first rows after encoding\n",
    "})\n",
    "print('X_train - Display the comparison between original and encoded labels')\n",
    "display(comparison_df_X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af5360",
   "metadata": {},
   "source": [
    "## 3. Apply TF-IDF Vectorization\n",
    "\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency) converts text data into numerical representations.  \n",
    "We set `max_features=5000` to limit the vocabulary size, ensuring efficiency while keeping relevant information.  \n",
    "We apply **`fit_transform()`** on `train_text` and **`transform()`** on `test_text` using the same TF-IDF model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15316a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 84916\n",
      "Testing samples: 13812\n"
     ]
    }
   ],
   "source": [
    "# Extract text column\n",
    "train_text = X_train['text']\n",
    "test_text = X_test['text']\n",
    "\n",
    "\n",
    "print(f\"Training samples: {train_text.shape[0]}\")\n",
    "print(f\"Testing samples: {test_text.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17998f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the TF-IDF X_train Matrix: (84916, 5000)\n",
      "Shape of the TF-IDF X_test Matrix: (13812, 5000)\n",
      "Sample of the TF-IDF X_train Matrix:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "Corresponding feature names (terms) for the sample:\n",
      "['aaa' 'abat' 'aberration' 'ability' 'abord']\n",
      "\n",
      "Sample of the TF-IDF X_test Matrix:\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "Corresponding feature names (terms) for the sample:\n",
      "['aaa' 'abat' 'aberration' 'ability' 'abord']\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit vocabulary size for efficiency\n",
    "\n",
    "# Fit and transform on training text\n",
    "X_train_matrix = tfidf.fit_transform(train_text)\n",
    "print(\"Shape of the TF-IDF X_train Matrix:\", X_train_matrix.shape)\n",
    "\n",
    "# Transform test text using the same vectorizer\n",
    "X_test_matrix = tfidf.transform(test_text)\n",
    "print(\"Shape of the TF-IDF X_test Matrix:\", X_test_matrix.shape)\n",
    "\n",
    "# Display a sample of the TF-IDF X_train matrix\n",
    "print(\"Sample of the TF-IDF X_train Matrix:\")\n",
    "print(X_train_matrix[:5, :5].toarray())  # Displaying a small portion of the matrix (5 rows and 5 columns)\n",
    "\n",
    "# Display the corresponding words (vocabulary terms) for the sample\n",
    "print(\"\\nCorresponding feature names (terms) for the sample:\")\n",
    "print(tfidf.get_feature_names_out()[:5])  # Display the first 5 feature names\n",
    "\n",
    "# Display a sample of the TF-IDF X_test matrix\n",
    "print(\"\\nSample of the TF-IDF X_test Matrix:\")\n",
    "print(X_test_matrix[:5, :5].toarray())  # Displaying a small portion of the matrix (5 rows and 5 columns)\n",
    "\n",
    "# Display the corresponding words (vocabulary terms) for the sample\n",
    "print(\"\\nCorresponding feature names (terms) for the sample:\")\n",
    "print(tfidf.get_feature_names_out()[:5])  # Display the first 5 feature names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31e723",
   "metadata": {},
   "source": [
    " ## 4. Save Encoded Labels, Product Mapping, and TF-IDF Data\n",
    " \n",
    "To ensure **reproducibility** and **efficient data handling**, we save the following files:\n",
    "\n",
    "✔ **`y_train_encoded.pkl`** → Encoded target labels for training data.  \n",
    "✔ **`X_train_final_encoded.pkl`** → Training dataset with a new column prdtypecode_encoded and a new column order.  \n",
    "✔ **`prdtypecode_mapping.csv`** → CSV file mapping original product codes to encoded targets.    \n",
    "✔ **`prdtypecode_mapping.pkl`** → Pickle version of the same mapping for easier loading.  \n",
    "✔ **`Xtrain_matrix.pkl`** → TF-IDF representation of the training data.    \n",
    "✔ **`Xtest_matrix.pkl`** → TF-IDF representation of the test data.    \n",
    "✔ **`tfidf_vectorizer.pkl`** → The trained vectorizer, ensuring we apply the same transformation later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63d15b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[✔] Target labels saved at: ../../data/processed/text/y_train_encoded.pkl\n",
      "\n",
      "[✔] X_train with encoded target saved at: ../../data/processed/X_train_final_encoded.pkl\n",
      "\n",
      "[✔] Mapping saved as CSV: ../../data/processed/text/prdtypecode_mapping.csv\n",
      "[✔] Mapping saved as Pickle: ../../data/processed/text/prdtypecode_mapping.pkl\n",
      "[✔] X_train_matrix saved at: ../../data/processed/text/Xtrain_matrix.pkl\n",
      "[✔] X_test_matrix saved at: ../../data/processed/text/Xtest_matrix.pkl\n",
      "[✔] TF-IDF vectorizer saved at: ../../data/processed/text/tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd  # Ensure Pandas is imported\n",
    "\n",
    "# Define the output directory for saving files\n",
    "TEXT_PROCESSED_DIR  = \"../../data/processed/text/\" # For text-related data\n",
    "GENERAL_PROCESSED_DIR = \"../../data/processed/\"    # For general processed data\n",
    "\n",
    "os.makedirs(TEXT_PROCESSED_DIR, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "os.makedirs(GENERAL_PROCESSED_DIR, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────── #\n",
    "# Save encoded target labels\n",
    "label_path = os.path.join(TEXT_PROCESSED_DIR, \"y_train_encoded.pkl\")\n",
    "y_train_encoded.to_pickle(label_path)\n",
    "print(f\"\\n[✔] Target labels saved at: {label_path}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────── #\n",
    "# Save the updated X_train with the encoded target\n",
    "X_train_encoded_path = os.path.join(GENERAL_PROCESSED_DIR, \"X_train_final_encoded.pkl\")\n",
    "X_train.to_pickle(X_train_encoded_path)\n",
    "\n",
    "print(f\"\\n[✔] X_train with encoded target saved at: {X_train_encoded_path}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────── #\n",
    "#  Create a mapping between original product codes and encoded targets\n",
    "mapping_df = pd.DataFrame(list(target_mapping.items()), columns=[\"Original prdtypecode\", \"Encoded target\"])\n",
    "\n",
    "# Add product labels from dictionary mapping\n",
    "mapping_df[\"Label\"] = mapping_df[\"Original prdtypecode\"].map(dict_code_label)\n",
    "\n",
    "#  Save the mapping as CSV and Pickle for future reference\n",
    "mapping_csv_path = os.path.join(TEXT_PROCESSED_DIR, \"prdtypecode_mapping.csv\")\n",
    "mapping_pkl_path = os.path.join(TEXT_PROCESSED_DIR, \"prdtypecode_mapping.pkl\")\n",
    "\n",
    "mapping_df.to_csv(mapping_csv_path, index=False)\n",
    "mapping_df.to_pickle(mapping_pkl_path)\n",
    "\n",
    "print(f\"\\n[✔] Mapping saved as CSV: {mapping_csv_path}\")\n",
    "print(f\"[✔] Mapping saved as Pickle: {mapping_pkl_path}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────── #\n",
    "#  Define file paths for matrices and the trained TF-IDF vectorizer\n",
    "file_paths = {\n",
    "    \"X_train_matrix\": os.path.join(TEXT_PROCESSED_DIR, \"Xtrain_matrix.pkl\"),\n",
    "    \"X_test_matrix\": os.path.join(TEXT_PROCESSED_DIR, \"Xtest_matrix.pkl\"),\n",
    "    \"TF-IDF vectorizer\": os.path.join(TEXT_PROCESSED_DIR, \"tfidf_vectorizer.pkl\")\n",
    "}\n",
    "\n",
    "#  Save matrices and TF-IDF vectorizer\n",
    "try:\n",
    "    pickle.dump(X_train_matrix, open(file_paths[\"X_train_matrix\"], \"wb\"))\n",
    "    pickle.dump(X_test_matrix, open(file_paths[\"X_test_matrix\"], \"wb\"))\n",
    "    pickle.dump(tfidf, open(file_paths[\"TF-IDF vectorizer\"], \"wb\"))\n",
    "\n",
    "    #  Verify if files were successfully saved\n",
    "    for name, path in file_paths.items():\n",
    "        if os.path.exists(path):\n",
    "            print(f\"[✔] {name} saved at: {path}\")\n",
    "        else:\n",
    "            print(f\"[X] Error: {name} was not saved.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[X] Error during saving: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be37d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification: First 5 rows of reloaded labels:\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: prdtypecode, dtype: int64\n",
      "\n",
      "Verification: Mapping (first 5 rows):\n",
      "   Original prdtypecode  Encoded target                    Label\n",
      "0                    10               0              Adult Books\n",
      "1                  2280               1                Magazines\n",
      "2                    50               2  Video Games Accessories\n",
      "3                  1280               3        Toys for Children\n",
      "4                  2705               4                    Books\n"
     ]
    }
   ],
   "source": [
    "# Reload labels and mapping to verify correctness\n",
    "y_train_encoded_check = pd.read_pickle(label_path)\n",
    "mapping_df_check = pd.read_pickle(mapping_pkl_path)\n",
    "\n",
    "print(\"\\nVerification: First 5 rows of reloaded labels:\")\n",
    "print(y_train_encoded_check.head())\n",
    "\n",
    "print(\"\\nVerification: Mapping (first 5 rows):\")\n",
    "print(mapping_df_check.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c52e1",
   "metadata": {},
   "source": [
    "## 5. 🔄 Next Steps\n",
    "\n",
    "Now that we have **vectorized our text data using TF-IDF**, a technique commonly employed in Machine Learning models, and **prepared our target labels**, we are ready to move on to the next phase: **Text Data Preparation for Deep Learning Models**.\n",
    "\n",
    "In the next step, we will focus on **tokenizing and sequencing our text data** to make it suitable for deep learning architectures. This involves:\n",
    "\n",
    "- **Tokenization**: Converting text into sequences of tokens (words or subwords) that can be processed by neural networks.\n",
    "- **Sequencing and Padding**: Ensuring all text sequences are of uniform length to efficiently batch and train models.\n",
    "\n",
    "These processes are crucial for the effective training of deep learning models on textual data.\n",
    "\n",
    "➡️ *Continue with the next notebook:*\n",
    "**`7_DL_Text_Tokenization_and_Sequencing.ipynb`**\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b3206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
